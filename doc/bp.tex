% LTeX: enabled=false
\documentclass[english, he, bc, kiv, iso690alph]{fasthesis}
\usepackage{csquotes} % gets an annoying warning off of my face
\author{Radomír}{Kesl}{}{}
\supervisor{Doc. Ing. Roman Mouček, Ph.D.}
\title{Neural networks for processing recordings of brain electrical activity}
% TODO:
\assignment{zadani.pdf}
\signdate{31}{12}{2022}{V Nové Vsi u Nového Města na Moravě}
\addbibresource{references.bib}
\abstract{Text abstraktu v jazyce práce , tj. zde česky.}
{The abstract text in a secondary language, here in English.}
\keywords{šablona kvalifikační práce ,sazba ,DTP ,\LaTeX}
\acknowledgement{Text poděkování.}
% ENDTODO:
\begin{document}

\frontpages[tm]
\tableofcontents

% LTeX: enabled=true
% LTeX: language=en-GB

\chapter{Introduction}

Complex recordings of human brain electrical activity could help us uncover various secrets of the human brain and its disorders, as well as make progress towards brain-controlled computers.
Recording brain activity has recently been becoming increasingly common, especially the very needed large-scale experiments have started to emerge. Processing these however tends to be a complex task which usually requires a lot of time-costly manual work and prior knowledge of human staff and might be subjected to human bias. Using artificial intelligence for these purposes thus seems like a natural approach, and since the patterns of the brain tend to be complicated, the very advanced neural networks might be a great technique for tackling this problem.
This paper first discusses the background of this area from various perspectives then focuses on the state-of-the-art before presenting ideas for consecutive research. Finally, a subset of these ideas is chosen and implemented.
The purpose of this research is to help advance extraction of information from recordings of human brain electrical activity in order to make them more useful  for future medical research or for direct use in brain-computer interfaces.
This paper focuses on the application of neural networks on data from recordings of electrical activity of the human brain for processing and extracting key information.

% TODO: When done, adjust this to contain the specific form of the work

\chapter{Background}

In this chapter various concepts, important for the area are explained in the following order. First the prevalent ways of recording brain activity are discussed, secondly examples of tasks which use neural networks and these recordings are presented, after that the basic types of modern neural networks are shown and finally data availability is briefly considered.

% TODO: Change this to reflect what actually is here

\section{Electroencephalography}

Electroencephalography (EEG) is possibly the most frequently used method of recording brain activity. It is conducted by planting electrodes on the scalp and making a record of the changing voltage (\cite{berger:eeg:29}, as cited by \cite{luck:erp:book}). This approach tends to be relatively convenient, as the required assets are not too costly, can be applied and removed non-invasively and even allow for user mobility~\cite{padfield:bci:19}.

One of the main advantages (along with the cost and convenience) of EEG is its great temporal resolution granted by the high speed of electric field propagation~\cite{roy:eeg:review:19}. On the other hand, the spatial resolution is often not great, which is caused by the tissues between the brain and the electrodes~\cite{roy:eeg:review:19, berezutskaya:ieeg:22}. A single electrode also obtains signals from several overlapping neural sources, leading to spatial correlation between the channels, making it difficult to isolate the desired information~\cite{roy:eeg:review:19, luck:erp:book}. In addition to that EEG also suffers noise from unrelated physiological signals, such as electromyogram from eye blinks~\cite{craik:dl:eeg:rev:19}.

It is worth noting that EEG can also be recorded intracranially (iEEG), possibly overcoming or at least reducing many of these issues. It is conducted by planting the electrodes directly on the brain tissue, which is obviously highly invasive and that tends to be a severe limitation, considering the risks and costs associated. There are, however, procedures that already involve the implantation process, such as localization of the source of epileptic seizures, or their treatment in durg-resistant patients~\cite{jobst:iEEG:20}. These provide a great opportunity to keep the records for other purposes as well~\cite{berezutskaya:ieeg:22}.

Lastly, one more disadvantage of EEG is high inter-subject variability caused by different physiology of subjects~\cite{roy:eeg:review:19}. This especially affects classification tasks that try to generalize over a large population. Intra-subject approach bypasses this problem, but introduces a new one --- the need for a large amount of data from each subject to train a unique classifier for them.

It appears that deep learning (DL) can be impactful in overcoming these limitations~\cite{roy:eeg:review:19}.

\section{Brain-computer Interface}

Using manual controls like buttons, joysticks or other physical movement is a serviceable but not very natural way of controlling assisting systems for the disabled~\cite{he:bci:legs:18}. This is only one of the areas, where brain-computer interface could be significantly beneficial~\cite{craik:dl:eeg:rev:19}.

As the name suggests, brain-computer interface (BCI), also referred to as brain-machine interface (BMI), could be defined as a system which allows direct communication between the human brain and a machine. However, controlling a BCI is typically challenging and requires extensive training, which still might be insufficient for some users~\cite{data:stieger:21}. The application of deep learning could help improve usability for users of varying proficiencies, making it easier to use for beginners and more precise for advanced users.

BCI technologies have a promising potential in various fields, such as prosthetics, rehabilitation and even entertainment.
In robotic prosthetics, BCIs could serve as an alternative to concurrent input methods, such as myoelectrics, which rely on relatively expensive technologies and are negatively affected by damage to the central nervous system~\cite{padfield:bci:19}. This also applies to wheelchair control and, in a sense, the control of a computer's cursor can fall in this category as well by providing even a seriously paralysed patient with numerous ways of interacting with the world.
In rehabilitation, robotic arms, exoskeletons and similar devices are often used to perform movements with the subjects' limbs in hopes of restoring the ability to do so on their own. In this practice, it is crucial for the subject to be imagining a movement of the limb and the device moving that limb in the imagined way. To achieve this, it is necessary to decode the imagination correctly, see section \ref{sec:mi}.
Another medical use of BCIs is affective computing, which is based on monitoring the subjects psychological state~\cite{padfield:bci:19}. This is a more passive approach, but the information is then used to for example adjust the subject's environment, so it can still be considered a BCI.
Finally, BCIs could be potentially used commercially in entertainment, for example gaming~\cite{padfield:bci:19}.

\section{Motor Imagery}
\label{sec:mi}

Motor imagery tasks seem to be among the most practical in BCI applications.
They rely on the subject imagining a movement of a part of their body without actually performing it~\cite{craik:dl:eeg:rev:19}.
The BCI then attempts to discern the imagined motion and passes the information to a connected system (assistant device, computer, \dots).

One of the main advantages of this approach is that motor imagery (imagining a movement) tends to have a similar effect on the brain as actually performing the movement~\cite{pfurtscheller:mi:01} which can help verify the accuracy of the measurement, among other neurophysiological benefits~[\emph{ibid.}].
That essentially means that we can record brain activity of subjects performing the movement and later compare it to the recordings from subjects imagining the movement to achieve better certainty that the data is valuable. If the data from motor imagery is nowhere near the data from performing movement, we can assume it is flawed (distracted subject, failed recording device, \dots) and exclude it from the final dataset.
It also means that we have a better idea of what to look for in the patterns of brain activity and that we could potentially feed this information to neural networks --- learn them on data from performing movements instead of (or as well as) imagining them.

Another advantage is that motor imagery simulates natural ways in which humans control their movement. For example, imagining walking could be used to control assistant devices, like a wheelchair (which is a lot more natural than a using a joystick or buttons), or a prosthetic leg. Similarly, imagining a movement of muscles in a limb could instruct an exoskeletal device to move this limb in the imagined way, which observed by the subject may help recover their ability to control the said limb (rehabilitative devices). Alternatively, imagining hand movement could be used to move the mouse cursor on a PC, which might be useful for anyone, but especially those suffering from any arm or hand related disabilities.


\section{Data Availability}

The lack of large, extensive datasets tends to be a problem while attempting to use neural networks on brain activity recordings. This is because complex classifiers, such as neural networks, while extremely precise with large amounts of data, tend to overfit easily in the case of insufficient data~\cite{domingos:ml:12}. This shortage seems to be mostly caused by the complexity of required experiments and the lack of appropriate subjects~\cite{he:da:21}. However, some studies that emerged recently appear reasonably extensive even for the use with these techniques.

Data augmentation (DA) --- a method of dealing with overfitting via generating additional data based on existing data --- tends to be a valuable tool in NN processing of brain activity recordings, because of the lack of complex datasets described earlier~\cite{he:da:21}. It carries some potential risks, such as reduced performance, but it usually succeeds in increasing accuracy of neural networks~[\emph{ibid.}].

\section{Deep Learning Classification}

% TODO: CNN, LSTM, Transformer

\subsection{Convolutional Neural Network}

\chapter{State-of-the-art}

In the following chapter, some state-of-the-art research is presented and evaluated for the purposes of further examination. First new open datasets of promising extensiveness are discussed and then examples of modern deep learning systems are shown.

\section{Datasets}

In this section, recent datasets are discussed in order to pick a good option for further experimenting. Each dataset has been assigned an alias (for convenience), as per table \ref{tab:aliases}. The examined sets have been recorded in table \ref{tab:datasets} and compared on metrics, such as size (amount of participants, trials and total recording time), metadata quality and availability. Further in this section a dataset is chosen and explained in detail. Note that this section is by no means meant to be a full review of the state-of-the-art datasets. It is a limited comparison with a goal of selecting a good set for our use. That means reasonably extensive, validated, equipped with metadata, accessible, and optimally already researched to an extent (other studies exist and can be used for comparison, but there is still space for further research).

The most of the comparison can be seen in table \ref{tab:datasets}. Note that trials and recording time are usually an approximation made by us or directly the authors of the dataset. The 'Citations' column contains the amount of times the data paper was cited on Web of Science at the time of writing this. The 'Metadata' column shows the quality of the metadata, attached to the dataset, where 'Sufficient' means at least gender, age and laterality; 'Insufficient' means anything less than that; and 'Extensive' means substantially more than that.
Based on our findings, the Stieger-62 dataset was chosen. The main reason is its size, which beats all the listed competition (and likely most of the unlisted as well) and while the Dreyer-87 dataset has a greater number of participants, the amount of trials and recording time in Stieger-62 is far superior, and we consider it more important. This dataset also fulfils all other requirements (validation, accessibility, \dots) and has a reasonable amount of citations. For those reasons it will be examined more closely and likely chosen for our experiments. If new issues appear about it, the Dreyer-87 dataset will be considered.

\begin{table}
	\centering
	\begin{tabular}{@{}p{0.15\textwidth}p{0.6\textwidth}p{0.15\textwidth}@{}}
		\toprule
		\textbf{Alias}        & \textbf{Article name}                                                                                    & \textbf{Citation}       \\
		\midrule
		Dreyer-87             & A large EEG database with users’ profile information for motor imagery brain-computer interface research & \cite{data:dreyer:23}   \\
		Ma-25                 & A large EEG dataset for studying cross-session variability in motor imagery brain-computer interface     & \cite{data:ma:22}       \\
		Peterson-10           & A motor imagery vs. rest dataset with low-cost consumer grade EEG hardware                               & \cite{data:peterson:22} \\
		Stieger-62            & Continuous sensorimotor rhythm based brain computer interface learning
		in a large population & \cite{data:stieger:21}                                                                                                             \\
		\bottomrule
	\end{tabular}
	\caption{Aliases of compared datasets.}
	\label{tab:aliases}
\end{table}

\begin{table}
	\centering
	\resizebox{\textwidth}{!}{
		\begin{tabular}{@{}*{9}{l}@{}}
			\toprule
			\textbf{Dataset} & \textbf{Participants} & \textbf{Trials} & \textbf{Recording time} & \textbf{Citations} & \textbf{Metadata} & \textbf{Validation} & \textbf{Availability} & \textbf{Licence} \\
			\midrule
			Dreyer-87        & 87                    & 20800           & 70 hours                & 0                  & Extensive         & Present             & Open Access           & CC BY 4.0        \\
			Ma-25            & 25                    & 12500           & 26 hours                & 6                  & Insufficient      & Present             & Open Access           & CC BY 4.0        \\
			Peterson-10      & 10                    & 1650            & 15 hours                & 1                  & Sufficient        & Missing             & Open Access           & CC0              \\
			Stieger-62       & 62                    & 250000          & 600 hours               & 15                 & Extensive         & Present             & Open Access           & CC BY 4.0        \\
			\bottomrule
		\end{tabular}
	}
	\caption{Comparison of recent datasets.}
	\label{tab:datasets}
\end{table}

% TODO: Review and edit

\subsection{Stieger-62 Dataset}

The Human EEG Dataset for Brain-Computer Interface and Meditation, collected by Stieger et al.~\cite{data:stieger:21} appears to be among the best in class with more than 250000 trials from 62 subjects, collected over 7--11 sessions.
The task in these experiments was moving a cursor via imagining hand movement. The subject was supposed to imagine opening and closing their left or right hand to move the cursor in the respective direction, opening and closing both hands at once to move the cursor up and clearing their mind to move the cursor down. Third of the trials was limited to up-down movement, third to left-right movement and the rest in both dimensions.
The 2D movement is a relatively uniquely complex task among BCI experiments.
Another important point is that one of the purposes of the study was to examine the evolving proficiency as the subject underwent successive sessions which could serve potential DL analysis.
Some subjects also received training in mindfulness and meditation, as examination of the effects of this training on BCI proficiency was among the main interests of the study~\cite{stieger:mindfulness:20}.

This, together with other metadata which is provided in great measure for the dataset, could be used to conduct various experiments in order to improve accuracy of the BCI using neural networks.
In this study a BCI was already used (online) to allow the users to control the cursor and thus be able to include the subjects' response to the visual feedback in the data. Nevertheless, a more classical approach to discern the subjects' intention was implemented, one based on actual neurophysiological knowledge of the expected EEG signal. Therefore, it seems natural to attempt to use a DL based method and compare the outcomes.

Recently, an extensive study has been conducted on the presented dataset by Zhu et al.~\cite{zhu:dl:bci:mi:22}, comparing state-of-the-art DL systems, conducting a within-subject analysis, as well as a cross-subject analysis. Only a limited subset of the Stieger-62 dataset was used by the authors in order to allow comparability to another dataset. Specifically, only one of three tasks was used --- moving the cursor from left to right, up-down movement and 2D movement were omitted. Additionally, only the first three sessions were used.
The following algorithms were used: EEGNet (CNN), Deep and Shallow ConvNet, Multi-Branch 3D CNN (CNN with 3D tensor input, arranged by spatial position on the scalp) and ParaAtt (Parallel Self-Attention Network). In the within-subject analysis, a model was built for each subject, using recordings from the first two sessions for training (20\% of that for validation) and data from the third session for testing. All the algorithms have outperformed the classical BCI used for online evaluation in the within-subject analysis. However, only EEGNet surpassed the online evaluation in a statistically significant way, achieving accuracy of $75.47 \pm 10.8\%$, while online achieved $68.10 \pm 12.6\%$.\@
For the cross-subject analysis, a model was also built for each subject, only this time using the first three sessions from that one subject as the test set  and the first three sessions of the remaining subjects as the training set (again, 20\% for validation). According to the authors of the study, EEGNet performed the best again (better than all the other models in a statistically significant way), but they do not provide the specific numbers.
This appears to be the only extensive study, conducted on the data of interest so far (and reasonably accessible to us), which leaves a decent amount of space for further studies while providing a possibility of comparison.

\section{Algorithms}

% TODO: CNN + LSTM, ...

\chapter{Analysis}

Ideas for future research in the application of neural networks on brain activity data are proposed in this chapter. Some of these will be selected for the final application. Firs new approaches on using specific data for training NNs in BCIs are suggested, then a more effective approach to storing data for experiments is discussed.

\section{Learning on Data from Trained Users}

According to Stieger et al.~\cite{data:stieger:21,stieger:mindfulness:20} users can improve in BCI proficiency via training. The question is: Could learning on recordings from these advanced users produce better classifiers than simply using all the available data? And would these be effective for any user or only those of comparable abilities?

This issue appears to be worth investigating via experimentation and the Med-62 dataset~\cite{data:stieger:21} could be very useful for that. Learning neural networks on this whole dataset and comparing the results to the same classifiers, learned on the later sessions only, could be  attempted. Also adding data augmentation to both of the experiments might produce interesting results --- the dataset is large enough, so that such a tool does not seem necessary, but it could still improve the accuracy, especially if only a part of the dataset is used.

Additionally, similar experiments could be performed with focus on users who received training in meditation instead of or in addition to using the later sessions.

\section{Metadata Specific Training}

Another approach that could be attempted is trying to find a classifier which would best work for a specific group of subjects based on a shared quality, such as gender, age and task-specific subject traits (such as dominant hand in the case of motor imagery). This could be done by training an entire subject-specific classifier which in case of long term used systems, such as BCI-operated assistant devices, would probably still be worth the extra work, or by pre-training a general classifier and then adding specializations for each user.

This approach seems to require a large amount of data equipped with profound metadata and once again, the Med-62 dataset~\cite{data:stieger:21} appears appropriate for that. In addition, as using subsets of datasets reduces the volume of the data significantly, data augmentation would likely be a worthwhile tool for these methods.

\section{Unified and Efficient Approach to Data}

Speaking from a completely different perspective, it does seem that this area of research could benefit from a more unified approach to some procedures, such as data recording and especially storage. A system where the data is in a single binary file could be designed. All the metadata could be in an external database or a similar system which would provide very fast access to any subset of the dataset, based on the metadata --- basically via simple queries.

A system like this could for example simplify the experiment procedure and increase the performance of metadata specific training discussed above. However, unification of the storage would probably be just useful in general, it could lead to better comparability between studies and much more complex and useful benchmarks.

\appendix
\chapter{Appendix A}

\backmatter
\printbibliography
\backpage

\end{document}


